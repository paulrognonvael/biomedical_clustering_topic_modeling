{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DBLBM_M3_CORD19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polrgn/biomedical_clustering_topic_modeling/blob/main/_appendix_DBLBM_M3_CORD19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJx1lCfEFjAG"
      },
      "source": [
        "# Application of the DBLBM $\\mathcal{M}_4$ to a corpus of COVID-19 publications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOKAdOzSF0qS"
      },
      "source": [
        "###DBLBM $\\mathcal{M}_4$ functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiPcFfp-Y5D-"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkRq1WNGGst3"
      },
      "source": [
        "Function for 'cold' random initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku9hcBxoY5EC"
      },
      "source": [
        "def cold_initialize(x,n,d,g):\n",
        "  while True:\n",
        "    z = np.zeros(shape=(n,g))\n",
        "    for i in range(0,n):\n",
        "      z[i,np.random.randint(g)] = 1\n",
        "\n",
        "    w = np.zeros(shape=(d,g))\n",
        "    for j in range(0,d):\n",
        "      w[j,np.random.randint(g)] = 1\n",
        "    \n",
        "    floor = np.empty(shape=(1,g))\n",
        "    floor[:] = 0\n",
        "    pi = np.maximum(np.sum(z,axis=0)/n,floor)[0]\n",
        "    rho = np.maximum(np.sum(w,axis=0)/d,floor)[0]\n",
        "\n",
        "    if (sum(pi==0)==0):\n",
        "      break\n",
        "\n",
        "  print('initial z:\\n',z[0:min(10,n),],'...')\n",
        "  print('initial w:\\n',w[0:min(10,d),],'...')\n",
        "  print('initial pi',pi)\n",
        "  print('initial rho',rho)\n",
        "  return z,w,pi,rho"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyEnoIXmG0k0"
      },
      "source": [
        "Function for 'warm' initialization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKqaSwW7m_kY"
      },
      "source": [
        "def warm_initialize(x,n,d,g):\n",
        "  while True:\n",
        "    km = MiniBatchKMeans(n_clusters=g, init='k-means++', n_init=10, \n",
        "                         batch_size=int(np.round(np.shape(x)[0]/10)))\n",
        "    km_cluster_labels_row = km.fit_predict(x)\n",
        "    z = np.zeros(shape=(n,g))\n",
        "    for i in range(0,n):\n",
        "      z[i,km_cluster_labels_row[i]] = 1\n",
        "\n",
        "    km = MiniBatchKMeans(n_clusters=g, init='k-means++', n_init=10,\n",
        "                         batch_size=int(np.round(np.shape(x)[1]/10)))\n",
        "    km_cluster_labels_col = km.fit_predict(np.transpose(x))\n",
        "    w = np.zeros(shape=(d,g))\n",
        "    for j in range(0,d):\n",
        "      w[j,km_cluster_labels_col[j]] = 1\n",
        "    \n",
        "    floor = np.empty(shape=(1,g))\n",
        "    floor[:] = 0\n",
        "    pi = np.maximum(np.sum(z,axis=0)/n,floor)[0]\n",
        "    rho = np.maximum(np.sum(w,axis=0)/d,floor)[0]\n",
        "\n",
        "    if (sum(pi==0)==0):\n",
        "      break\n",
        "\n",
        "  print('initial z:\\n',z[0:min(10,n),],'...')\n",
        "  print('initial w:\\n',w[0:min(10,d),],'...')\n",
        "  print('initial pi',pi)\n",
        "  print('initial rho',rho)\n",
        "  return z,w,pi,rho,km_cluster_labels_row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUcoqQFYY5EF"
      },
      "source": [
        "# Get epsilon hat\n",
        "def eps_hat_funct (z,w,x,n,d,g):\n",
        "  vect_x_kk_zw = np.empty(shape=g)\n",
        "  vect_x_kk_zw[:]= np.NaN\n",
        "  for k in range(0,g):\n",
        "    x_kk_zw = 0\n",
        "    for i in range(0,n):\n",
        "      for j in range(0,d):\n",
        "        x_kk_zw = x_kk_zw + z[i,k]*w[j,k]*x[i,j]\n",
        "    vect_x_kk_zw[k] = x_kk_zw\n",
        "\n",
        "  term_1 = np.sum(np.abs(vect_x_kk_zw - np.sum(z,axis=0)*np.sum(w,axis=0)))\n",
        "\n",
        "  sum_x_kl_zw = 0\n",
        "  #counter = 0\n",
        "  for k in range(0,g):\n",
        "    for l in range(0,g):\n",
        "      if l == k : \n",
        "        continue\n",
        "      x_kl_zw = 0\n",
        "      for i in range(0,n):\n",
        "        for j in range(0,d):\n",
        "          x_kl_zw = x_kl_zw + z[i,k]*w[j,l]*x[i,j]\n",
        "      sum_x_kl_zw = sum_x_kl_zw + x_kl_zw\n",
        "      #counter +=1\n",
        "      #print(counter)\n",
        "\n",
        "  eps_hat = max((term_1 + sum_x_kl_zw)/(n*d),0.01)\n",
        "  return(eps_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUwheCpYY5EH"
      },
      "source": [
        "# Get Aik's\n",
        "def get_Aiks(z,w,x,pi,n,d,g):\n",
        "  A = np.empty(shape=(n,g))\n",
        "  A[:]= np.NaN\n",
        "  for i in range(0,n):\n",
        "    for k in range(0,g):\n",
        "      xik_w = 0\n",
        "      w_j = 0\n",
        "      for j in range(0,d):\n",
        "        xik_w = xik_w + w[j,k]*x[i,j]\n",
        "        w_j = w_j + w[j,k]\n",
        "      term1 = np.abs(xik_w- w_j)\n",
        "\n",
        "      sum_x_il_w = 0\n",
        "      for l in range(0,g):\n",
        "        if l == k : \n",
        "          continue\n",
        "        x_il_w = 0\n",
        "        for j in range(0,d):\n",
        "          x_il_w = x_il_w + w[j,l]*x[i,j]\n",
        "        sum_x_il_w = sum_x_il_w + x_il_w\n",
        "      \n",
        "      A[i,k] = -(term1 + sum_x_il_w)\n",
        "  return A\n",
        "\n",
        "def update_z(z,A,n):\n",
        "  z_update = np.copy(z)\n",
        "  for i in range(0,n):\n",
        "    z_update[i,:] = 0\n",
        "    k_star = np.where(A[i,:]==np.max(A[i,:]))[0][0]\n",
        "    z_update[i,int(k_star)] = 1\n",
        "  return z_update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdyPNgX0Y5EJ"
      },
      "source": [
        "def maximize_classlikelihood_wrt_z(z,w,x,pi,n,d,g):\n",
        "  current_w = np.copy(w)\n",
        "  current_z = np.copy(z)\n",
        "  current_pi = np.copy(pi)\n",
        "\n",
        "  while True:\n",
        "    A=get_Aiks(current_z,current_w,x,current_pi,n,d,g)\n",
        "    updated_z = update_z(current_z,A,n)\n",
        "    floor = np.empty(shape=(1,g))\n",
        "    floor[:] = 0\n",
        "    updated_pi = np.maximum(np.sum(updated_z,axis=0)/n,floor)[0]\n",
        "    \n",
        "    diff_z = np.sum(np.abs(updated_z-current_z))/np.sum(current_z)\n",
        "    diff_pi = np.sum(np.abs(updated_pi-current_pi))/np.sum(current_pi)\n",
        " \n",
        "    current_z = updated_z\n",
        "    current_pi = updated_pi\n",
        "    \n",
        "    if((diff_z<=0.01) and (diff_pi<=0.01)):\n",
        "      break\n",
        "      \n",
        "  return current_z, current_pi\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUt_gmbvY5EL"
      },
      "source": [
        "# Get Bjl's\n",
        "def get_Bjls(z,w,x,rho,n,d,g):\n",
        "  B = np.empty(shape=(d,g))\n",
        "  B[:]= np.NaN\n",
        "  for j in range(0,d):\n",
        "    for l in range(0,g):\n",
        "      xlj_z = 0\n",
        "      z_l = 0\n",
        "      for i in range(0,n):\n",
        "        xlj_z = xlj_z + z[i,l]*x[i,j]\n",
        "        z_l = z_l + z[i,l]\n",
        "      term1 = np.abs(xlj_z- z_l)\n",
        "\n",
        "      sum_x_kj_z = 0\n",
        "      for k in range(0,g):\n",
        "        if k == l : \n",
        "          continue\n",
        "        x_kj_z = 0\n",
        "        for i in range(0,n):\n",
        "          x_kj_z = x_kj_z + z[i,k]*x[i,j]\n",
        "        sum_x_kj_z = sum_x_kj_z + x_kj_z\n",
        "\n",
        "      B[j,l] = -(term1 + sum_x_kj_z)\n",
        "  return B\n",
        "\n",
        "def update_w(w,B,d):\n",
        "  w_update = np.copy(w)\n",
        "  for j in range(0,d):\n",
        "    w_update[j,:] = 0\n",
        "    l_star = np.where(B[j,:]==np.max(B[j,:]))[0][0]\n",
        "    w_update[j,int(l_star)] = 1\n",
        "  return w_update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb0ta-O9Y5EM"
      },
      "source": [
        "def maximize_classlikelihood_wrt_w(z,w,x,rho,n,d,g):\n",
        "  current_w = np.copy(w)\n",
        "  current_z = np.copy(z)\n",
        "  current_rho = np.copy(rho)\n",
        "\n",
        "  while True:\n",
        "    B=get_Bjls(current_z,current_w,x,current_rho,n,d,g)\n",
        "    updated_w = update_w(current_w,B,d)\n",
        "    floor = np.empty(shape=(1,g))\n",
        "    floor[:] = 0\n",
        "    updated_rho = np.maximum(np.sum(updated_w,axis=0)/d,floor)[0]\n",
        "\n",
        "    diff_w = np.sum(np.abs(updated_w-current_w))/np.sum(current_w)\n",
        "    diff_rho = np.sum(np.abs(updated_rho-current_rho))/np.sum(current_rho)\n",
        " \n",
        "    current_w = updated_w\n",
        "    current_rho = updated_rho\n",
        "    \n",
        "    if((diff_w<=0.01) and (diff_rho<=0.01)):\n",
        "      break\n",
        "      \n",
        "  return current_w, current_rho"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfSnwHxMY5EN"
      },
      "source": [
        "def maximize_classlikelihood(z,w,x,pi,rho,n,d,g):\n",
        "  current_z = np.copy(z)\n",
        "  current_w = np.copy(w)\n",
        "  current_pi = np.copy(pi)\n",
        "  current_rho = np.copy(rho)\n",
        "\n",
        "  while True:\n",
        "    print('\\nMaximizing with respect to z\\n')\n",
        "    updated_z, updated_pi = maximize_classlikelihood_wrt_z(current_z,current_w,x,current_pi,n,d,g)\n",
        "    print('\\nMaximizing with respect to w\\n')\n",
        "    updated_w, updated_rho = maximize_classlikelihood_wrt_w(updated_z,current_w,x,current_rho,n,d,g)\n",
        "    \n",
        "    diff_z = np.sum(np.abs(updated_z-current_z))/np.sum(current_z)\n",
        "    diff_w = np.sum(np.abs(updated_w-current_w))/np.sum(current_w)\n",
        "    diff_pi = np.sum(np.abs(updated_pi-current_pi))/np.sum(current_pi)\n",
        "    diff_rho = np.sum(np.abs(updated_rho-current_rho))/np.sum(current_rho)\n",
        "\n",
        "    current_z = updated_z\n",
        "    current_w = updated_w\n",
        "    current_pi = updated_pi\n",
        "    current_rho = updated_rho\n",
        "    \n",
        "    if((diff_z<=0.01) and (diff_w<=0.01) and (diff_pi<=0.01) and (diff_rho<=0.01)):\n",
        "      break\n",
        "    \n",
        "  return current_z, current_w, current_pi, current_rho"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_xYk45IY5EP"
      },
      "source": [
        "def compute_loglikelihood(z,w,x,pi,rho,eps,n,d,g):\n",
        "  L_C = np.log(1-eps)*n*d\n",
        "  for i in range(0,n):\n",
        "    for k in range(0,g):\n",
        "      add = z[i,k]*np.log(pi[k])\n",
        "      if ~np.isnan(add):\n",
        "        L_C = L_C + add\n",
        "      for j in range(0,d):\n",
        "        add = (np.log(eps)-np.log(1-eps))*z[i,k]*w[j,k]*np.abs(x[i,j]-1)\n",
        "        if ~np.isnan(add):\n",
        "          L_C= L_C + add\n",
        "  \n",
        "  for j in range(0,d):\n",
        "    for l in range(0,g):\n",
        "      add = w[j,l]*np.log(rho[l])\n",
        "      if ~np.isnan(add):\n",
        "        L_C = L_C + add\n",
        "\n",
        "  for i in range(0,n):\n",
        "    for j in range(0,d):\n",
        "      for k in range(0,g):\n",
        "        for l in range(0,g):\n",
        "          if l == k : \n",
        "            continue\n",
        "          add = (np.log(eps)-np.log(1-eps))*z[i,k]*w[j,l]*x[i,j]\n",
        "          if ~np.isnan(add):\n",
        "            L_C = L_C + add\n",
        "  return L_C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REJH6189Y5EQ"
      },
      "source": [
        "def get_predicted_lab(z,n):\n",
        "  labels_pred = np.empty(shape=(n,1))\n",
        "  labels_pred[:]= np.NaN\n",
        "  for i in range(0,n):\n",
        "    labels_pred[i,0] = np.where(z[i,:]==1)[0]\n",
        "  return labels_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgyBkKn2xxZs"
      },
      "source": [
        "### Application of a sample of CORD-19 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfp2Nr90GPI-"
      },
      "source": [
        "We import the libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVFUNDtdyZHM"
      },
      "source": [
        "import pandas as pd\n",
        "import scipy.sparse\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFnjTYsjxxJf",
        "outputId": "bde9ad19-7e69-45dd-ea87-aaa78e996471"
      },
      "source": [
        "# Mounting Google drive where we save our data and embeddings\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z04nL9PGSMG"
      },
      "source": [
        "We read the pre-processed abstracts and obtain the binary document-term matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnL2hGuCkBXQ"
      },
      "source": [
        "N = 10000\n",
        "abstract_df = pd.read_csv('drive/MyDrive/Project_Graph/abstract_df_clean_stopwords_lang_abstrlen.csv',index_col=0)\n",
        "abstract_df = abstract_df[0:N]\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features = 5000, max_df = 0.3, min_df=0.05)\n",
        "tf_idf_vectorizer = vectorizer.fit(abstract_df.abstract)\n",
        "tf_idf_matrix = vectorizer.transform(abstract_df.abstract)\n",
        "scipy.sparse.save_npz('drive/MyDrive/Project_Graph/tfidf_abstract', tf_idf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3Rt5QWwxw5X",
        "outputId": "e0cf3410-5d52-48d8-833c-7cc05cce2f33"
      },
      "source": [
        "tfidf_view = scipy.sparse.load_npz('drive/MyDrive/Project_Graph/tfidf_abstract.npz')\n",
        "tfidf_view_array = np.squeeze(np.asarray(tfidf_view.todense()))\n",
        "print('Sparsity TF-IDF',sum(sum(tfidf_view_array==0))/(np.shape(tfidf_view_array)[0]*np.shape(tfidf_view_array)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity TF-IDF 0.923709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9ZDvjzOyxmT",
        "outputId": "fae6c5a1-15bc-4f11-c3fd-ada87ac129b6"
      },
      "source": [
        "x_tfidf = np.copy(tfidf_view_array)\n",
        "x_bin = np.copy(tfidf_view_array)\n",
        "x_bin[x_bin != 0] = 1\n",
        "np.unique(tfidf_view_array)\n",
        "print('Sparsity TF-IDF',sum(sum(tfidf_view_array==0))/(np.shape(tfidf_view_array)[0]*np.shape(tfidf_view_array)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity TF-IDF 0.923709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jvDv7hPGeGX"
      },
      "source": [
        "We run the DBLM $\\mathcal{M}_3$ on the binary document-term matrix and K-means on the TF-IDF representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvwagwQEzEk8",
        "outputId": "5ebd984a-c43e-4333-d87b-6a17910f13d5"
      },
      "source": [
        "n = np.shape(x_bin)[0]\n",
        "d = np.shape(x_bin)[1]\n",
        "range_g = [3,4,5,6]\n",
        "labels_array_dblbm = np.empty(shape=(n,len(range_g)))\n",
        "labels_array_km = np.empty(shape=(n,len(range_g)))\n",
        "loglikelihood_dblbm = []\n",
        "silhouette_dblbm = []\n",
        "ch_dblbm = []\n",
        "db_dblbm = []\n",
        "silhouette_km = []\n",
        "ch_km = []\n",
        "db_km = []\n",
        "\n",
        "i = 0\n",
        "for g in range_g:\n",
        "  # cold initialization\n",
        "  #z0,w0,pi0,rho0,eps0= cold_initialize(x,n,d,g)\n",
        "  # warm initialization\n",
        "  z0,w0,pi0,rho0,labels_km = warm_initialize(x_tfidf,n,d,g)\n",
        "  \n",
        "  optim_z, optim_w, optim_pi, optim_rho = maximize_classlikelihood(z0,w0,x_bin,pi0,rho0,n,d,g)\n",
        "  optim_eps = eps_hat_funct(optim_z, optim_w, x_bin, n, d, g)\n",
        "  labels_array_dblbm[:,i] = get_predicted_lab(optim_z,n)[:,0]\n",
        "  labels_array_km[:,i] = labels_km\n",
        "  loglikelihood_dblbm.append(compute_loglikelihood(optim_z, optim_w, x_bin, optim_pi, optim_rho, optim_eps,n,d,g))\n",
        "  silhouette_km.append(metrics.silhouette_score(x_tfidf, labels_km))\n",
        "  ch_km.append(metrics.calinski_harabasz_score(x_tfidf, labels_km))\n",
        "  db_km.append(metrics.davies_bouldin_score(x_tfidf, labels_km))\n",
        "  silhouette_dblbm.append(metrics.silhouette_score(x_bin, labels_km))\n",
        "  ch_dblbm.append(metrics.calinski_harabasz_score(x_bin, labels_km))\n",
        "  db_dblbm.append(metrics.davies_bouldin_score(x_bin, labels_km))\n",
        "  i +=1\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial z:\n",
            " [[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]] ...\n",
            "initial w:\n",
            " [[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]] ...\n",
            "initial pi [0.3665 0.2218 0.4117]\n",
            "initial rho [0.005 0.02  0.975]\n",
            "\n",
            "Maximizing with respect to z\n",
            "\n",
            "\n",
            "Maximizing with respect to w\n",
            "\n",
            "\n",
            "Maximizing with respect to z\n",
            "\n",
            "\n",
            "Maximizing with respect to w\n",
            "\n",
            "\n",
            "Maximizing with respect to z\n",
            "\n",
            "\n",
            "Maximizing with respect to w\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "initial z:\n",
            " [[0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]] ...\n",
            "initial w:\n",
            " [[0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]] ...\n",
            "initial pi [0.2269 0.2907 0.1885 0.2939]\n",
            "initial rho [0.005 0.005 0.015 0.975]\n",
            "\n",
            "Maximizing with respect to z\n",
            "\n",
            "\n",
            "Maximizing with respect to w\n",
            "\n",
            "\n",
            "Maximizing with respect to z\n",
            "\n",
            "\n",
            "Maximizing with respect to w\n",
            "\n",
            "\n",
            "Maximizing with respect to z\n",
            "\n",
            "\n",
            "Maximizing with respect to w\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "initial z:\n",
            " [[0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]] ...\n",
            "initial w:\n",
            " [[0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]] ...\n",
            "initial pi [0.0418 0.1929 0.2717 0.2806 0.213 ]\n",
            "initial rho [0.295 0.005 0.69  0.005 0.005]\n",
            "\n",
            "Maximizing with respect to z\n",
            "\n",
            "\n",
            "Maximizing with respect to w\n",
            "\n",
            "\n",
            "Maximizing with respect to z\n",
            "\n",
            "\n",
            "Maximizing with respect to w\n",
            "\n",
            "\n",
            "Maximizing with respect to z\n",
            "\n",
            "\n",
            "Maximizing with respect to w\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "initial z:\n",
            " [[0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]] ...\n",
            "initial w:\n",
            " [[0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]] ...\n",
            "initial pi [0.2063 0.0468 0.2534 0.0458 0.2354 0.2123]\n",
            "initial rho [0.005 0.005 0.005 0.96  0.02  0.005]\n",
            "\n",
            "Maximizing with respect to z\n",
            "\n",
            "\n",
            "Maximizing with respect to w\n",
            "\n",
            "\n",
            "Maximizing with respect to z\n",
            "\n",
            "\n",
            "Maximizing with respect to w\n",
            "\n",
            "\n",
            "Maximizing with respect to z\n",
            "\n",
            "\n",
            "Maximizing with respect to w\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHKCRFLy1TE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694438b3-95d8-4e4e-f59b-afe95ed3c2bb"
      },
      "source": [
        "for i in range(0,len(range_g)):\n",
        "  unique, counts = np.unique(labels_array_dblbm[:,i], return_counts=True)\n",
        "  print('DBLBM','g=',range_g[i],dict(zip(unique, counts)))\n",
        "  unique, counts = np.unique(labels_array_km[:,i], return_counts=True)\n",
        "  print('KM','g=',range_g[i],dict(zip(unique, counts)))\n",
        "\n",
        "results_km = pd.DataFrame({'n_cluster':range_g,'silhouette':silhouette_km,\n",
        "                          'CH_score':ch_km, 'DB_score':db_km})\n",
        "results_dblbm = pd.DataFrame({'n_cluster':range_g,'silhouette':silhouette_dblbm,\n",
        "                          'CH_score':ch_dblbm, 'DB_score':db_dblbm,\n",
        "                          'loglikelihood':loglikelihood_dblbm})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DBLBM g= 3 {0.0: 9503, 1.0: 497}\n",
            "KM g= 3 {0.0: 3665, 1.0: 2218, 2.0: 4117}\n",
            "DBLBM g= 4 {0.0: 8858, 1.0: 878, 2.0: 264}\n",
            "KM g= 4 {0.0: 2269, 1.0: 2907, 2.0: 1885, 3.0: 2939}\n",
            "DBLBM g= 5 {1.0: 8417, 3.0: 1113, 4.0: 470}\n",
            "KM g= 5 {0.0: 418, 1.0: 1929, 2.0: 2717, 3.0: 2806, 4.0: 2130}\n",
            "DBLBM g= 6 {0.0: 7808, 1.0: 559, 2.0: 549, 4.0: 131, 5.0: 953}\n",
            "KM g= 6 {0.0: 2063, 1.0: 468, 2.0: 2534, 3.0: 458, 4.0: 2354, 5.0: 2123}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufQnnovb2eEP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "2110fb92-2d9b-45d3-cddd-2a92809360a3"
      },
      "source": [
        "results_dblbm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_cluster</th>\n",
              "      <th>silhouette</th>\n",
              "      <th>CH_score</th>\n",
              "      <th>DB_score</th>\n",
              "      <th>loglikelihood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0.004696</td>\n",
              "      <td>108.280410</td>\n",
              "      <td>7.861541</td>\n",
              "      <td>-538736.919746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.008979</td>\n",
              "      <td>97.244395</td>\n",
              "      <td>7.806006</td>\n",
              "      <td>-540480.519302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>-0.002098</td>\n",
              "      <td>81.072013</td>\n",
              "      <td>7.644597</td>\n",
              "      <td>-540618.928707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>-0.003652</td>\n",
              "      <td>74.197820</td>\n",
              "      <td>7.249360</td>\n",
              "      <td>-541395.135187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   n_cluster  silhouette    CH_score  DB_score  loglikelihood\n",
              "0          3    0.004696  108.280410  7.861541 -538736.919746\n",
              "1          4   -0.008979   97.244395  7.806006 -540480.519302\n",
              "2          5   -0.002098   81.072013  7.644597 -540618.928707\n",
              "3          6   -0.003652   74.197820  7.249360 -541395.135187"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AapY6Hz2Z4y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "9ce5c78f-c12b-4bbc-fed0-2bc3cb51f825"
      },
      "source": [
        "results_km"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_cluster</th>\n",
              "      <th>silhouette</th>\n",
              "      <th>CH_score</th>\n",
              "      <th>DB_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0.015620</td>\n",
              "      <td>126.910269</td>\n",
              "      <td>7.710810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>0.015550</td>\n",
              "      <td>109.096849</td>\n",
              "      <td>7.668895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>0.018126</td>\n",
              "      <td>108.760701</td>\n",
              "      <td>6.761509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>0.019995</td>\n",
              "      <td>103.202757</td>\n",
              "      <td>6.369907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   n_cluster  silhouette    CH_score  DB_score\n",
              "0          3    0.015620  126.910269  7.710810\n",
              "1          4    0.015550  109.096849  7.668895\n",
              "2          5    0.018126  108.760701  6.761509\n",
              "3          6    0.019995  103.202757  6.369907"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9n0JXxiG6la"
      },
      "source": [
        "We compute the ICL for the DBLM $\\mathcal{M}_3$ outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt58VndocKV7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "0faa8df5-3497-405f-ec18-f67535a54548"
      },
      "source": [
        "ICL =[]\n",
        "for i in range(0,len(range_g)):\n",
        "  icl_g = results_dblbm.loc[i,'loglikelihood'] - 2*np.log(n)*(range_g[i]-1)/2 - np.log(n*d)/2\n",
        "  ICL.append(icl_g)\n",
        "results_dblbm['ICL'] = ICL\n",
        "results_dblbm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_cluster</th>\n",
              "      <th>silhouette</th>\n",
              "      <th>CH_score</th>\n",
              "      <th>DB_score</th>\n",
              "      <th>loglikelihood</th>\n",
              "      <th>ICL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0.004696</td>\n",
              "      <td>108.280410</td>\n",
              "      <td>7.861541</td>\n",
              "      <td>-538736.919746</td>\n",
              "      <td>-538762.594756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.008979</td>\n",
              "      <td>97.244395</td>\n",
              "      <td>7.806006</td>\n",
              "      <td>-540480.519302</td>\n",
              "      <td>-540515.404652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>-0.002098</td>\n",
              "      <td>81.072013</td>\n",
              "      <td>7.644597</td>\n",
              "      <td>-540618.928707</td>\n",
              "      <td>-540663.024397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>-0.003652</td>\n",
              "      <td>74.197820</td>\n",
              "      <td>7.249360</td>\n",
              "      <td>-541395.135187</td>\n",
              "      <td>-541448.441218</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   n_cluster  silhouette    CH_score  DB_score  loglikelihood            ICL\n",
              "0          3    0.004696  108.280410  7.861541 -538736.919746 -538762.594756\n",
              "1          4   -0.008979   97.244395  7.806006 -540480.519302 -540515.404652\n",
              "2          5   -0.002098   81.072013  7.644597 -540618.928707 -540663.024397\n",
              "3          6   -0.003652   74.197820  7.249360 -541395.135187 -541448.441218"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syMxzTuGe1Zu"
      },
      "source": [
        "results_km.to_csv('drive/MyDrive/Project_Graph/results_km_m4.csv')\n",
        "results_dblbm.to_csv('drive/MyDrive/Project_Graph/results_dblbm_m4.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW5JzYTpHE9D"
      },
      "source": [
        "We extract the top words by cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "311VtuJeowak"
      },
      "source": [
        "def get_topwords3(data,k):\n",
        "    countvectorizer = CountVectorizer(ngram_range=(1,2), max_features = 5000, max_df = 0.4, stop_words=list_stop_words)\n",
        "    data_vectorized = countvectorizer.fit_transform(data)\n",
        "    word_df = pd.DataFrame({'word': countvectorizer.get_feature_names(), 'count': np.asarray(data_vectorized.sum(axis=0))[0]})\n",
        "    tfidfvectorizer = TfidfVectorizer(ngram_range=(1,1),vocabulary= countvectorizer.vocabulary_)\n",
        "    word_df['idf'] = list(tfidfvectorizer.fit(data).idf_.flatten())\n",
        "    word_df['custom_index'] = scale(word_df['count']*word_df['idf'])\n",
        "    word_df = word_df.sort_values(by='custom_index', ascending=False)\n",
        "    return word_df.head(k)\n",
        "\n",
        "def get_topwords_bycluster(df,cluster_var,n_clust,n_topword):\n",
        "  topwords_glob = pd.DataFrame()\n",
        "  for i in range(0,n_clust):\n",
        "        data = df[df[cluster_var]==i]['abstract']\n",
        "        print('cluster',i)\n",
        "        #print(get_topwords(data,15),'\\n')\n",
        "        #print(get_topwords2(data,15),'\\n')\n",
        "        topword_clust = get_topwords3(data,n_topword)\n",
        "        print(topword_clust[['word','custom_index']],'\\n')\n",
        "        topword_clust['cluster'] = str(i)\n",
        "        topwords_glob = pd.concat([topwords_glob,topword_clust[['cluster','word','custom_index']]],axis=0)\n",
        "  return topwords_glob\n",
        "\n",
        "list_stop_words = np.load(\"drive/MyDrive/Project_Graph/list_stopwords.npz\")\n",
        "list_stop_words = list(list_stop_words['arr_0'])\n",
        "\n",
        "dblbm_labels = labels_array_dblbm[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Yl2tmFNo8sK",
        "outputId": "78cc00ff-9ccd-4727-f95e-c221adb0c7e5"
      },
      "source": [
        "abstract_df_clusterized = abstract_df\n",
        "abstract_df_clusterized['cluster_km'] = labels_array_km[:,2]\n",
        "abstract_df_clusterized['cluster_dblbm'] = dblbm_labels\n",
        "\n",
        "get_topwords_bycluster(abstract_df_clusterized,'cluster_km',5,15).to_csv('drive/MyDrive/Project_Graph/topword_clust_km_m4.csv')\n",
        "get_topwords_bycluster(abstract_df_clusterized,'cluster_dblbm',4-1,15).to_csv('drive/MyDrive/Project_Graph/topword_clust_dblbm_m4.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cluster 0\n",
            "                  word  custom_index\n",
            "2767              mers     17.564375\n",
            "2812       middle east     14.166778\n",
            "1453     east syndrome     12.618761\n",
            "4627     syndrome mers     11.999554\n",
            "62                ace2      9.769098\n",
            "417            binding      8.697259\n",
            "551               cell      8.015864\n",
            "3986               rna      8.001317\n",
            "3745  receptor binding      7.974709\n",
            "4291          specific      7.410478\n",
            "252           antibody      7.333876\n",
            "3705               rbd      7.224636\n",
            "244         antibodies      7.037267\n",
            "4880           vaccine      6.769362\n",
            "2160               igg      6.731265 \n",
            "\n",
            "cluster 1\n",
            "                 word  custom_index\n",
            "699              cell     14.976859\n",
            "4914          viruses     12.383557\n",
            "2230           immune     10.853341\n",
            "2236  immune response      9.701527\n",
            "4064              rna      8.872637\n",
            "2134             host      8.863139\n",
            "1698       expression      8.662374\n",
            "109          activity      8.602126\n",
            "4006         response      8.180400\n",
            "4343         specific      7.776373\n",
            "3556        potential      7.493182\n",
            "3733         proteins      7.255960\n",
            "4086             role      6.849071\n",
            "491           binding      6.758145\n",
            "2336       infections      6.688080 \n",
            "\n",
            "cluster 2\n",
            "               word  custom_index\n",
            "1797      follow up     11.534452\n",
            "209             age      9.319820\n",
            "4967          years      8.529995\n",
            "217       age years      8.336198\n",
            "1132           days      7.990305\n",
            "4483       symptoms      7.935467\n",
            "3140       outcomes      7.840072\n",
            "2183      increased      7.439504\n",
            "4173  significantly      7.401301\n",
            "3705           rate      6.889185\n",
            "4452        surgery      6.851354\n",
            "1938         groups      6.821966\n",
            "2668           mean      6.780756\n",
            "740        children      6.712714\n",
            "2486         levels      6.679436 \n",
            "\n",
            "cluster 3\n",
            "                   word  custom_index\n",
            "4223             social     11.528172\n",
            "3588             public     10.316545\n",
            "4224  social distancing     10.211295\n",
            "3870           research     10.160369\n",
            "2256        information      8.622052\n",
            "4495             system      8.115289\n",
            "3219             people      7.628386\n",
            "2024         healthcare      7.616918\n",
            "2706           measures      7.157493\n",
            "2154             impact      7.124197\n",
            "2721            medical      7.000481\n",
            "3052             online      6.732289\n",
            "1931             global      6.602048\n",
            "2503           learning      6.583080\n",
            "4562            testing      6.481996 \n",
            "\n",
            "cluster 4\n",
            "              word  custom_index\n",
            "580           case     12.278830\n",
            "2630          lung     10.556605\n",
            "4685  transmission     10.369320\n",
            "2689    management      9.127552\n",
            "3030        number      8.983837\n",
            "684          china      8.752651\n",
            "4518      symptoms      8.340286\n",
            "4521      syndrome      8.149339\n",
            "3379     pneumonia      8.096588\n",
            "3983        review      8.060580\n",
            "1228     diagnosis      7.910385\n",
            "1520      epidemic      7.718258\n",
            "1006     countries      7.675907\n",
            "1284      diseases      7.389728\n",
            "3896      reported      7.283411 \n",
            "\n",
            "cluster 0\n",
            "           word  custom_index\n",
            "623        cell      6.777903\n",
            "4511   symptoms      6.368485\n",
            "4522     system      5.963695\n",
            "3057     number      5.889683\n",
            "152         age      5.847437\n",
            "1794  follow up      5.826781\n",
            "3438  potential      5.819012\n",
            "3983     review      5.812040\n",
            "4977      years      5.773986\n",
            "2760    medical      5.756035\n",
            "3030        non      5.719766\n",
            "3736       rate      5.667153\n",
            "2212  increased      5.664276\n",
            "3898   reported      5.630407\n",
            "4514   syndrome      5.558881 \n",
            "\n",
            "cluster 1\n",
            "                   word  custom_index\n",
            "4202  social distancing     28.450474\n",
            "4215       social media     13.505586\n",
            "2637           measures      8.919589\n",
            "1223         distancing      8.571531\n",
            "3581             public      8.120081\n",
            "3177             people      7.091924\n",
            "2208        information      6.819618\n",
            "2688             mental      6.617880\n",
            "2084             impact      6.568013\n",
            "4455            support      6.487531\n",
            "2651              media      6.459824\n",
            "2524           lockdown      6.380893\n",
            "3126       participants      6.356290\n",
            "3324         population      5.842454\n",
            "218             anxiety      5.723022 \n",
            "\n",
            "cluster 2\n",
            "               word  custom_index\n",
            "548            cell     10.126439\n",
            "1631     expression      9.292706\n",
            "2612         levels      8.873334\n",
            "1988         groups      7.825934\n",
            "2330      increased      7.560404\n",
            "4259  significantly      6.907688\n",
            "3992       response      6.881722\n",
            "1382        effects      6.359335\n",
            "4099            rsv      6.317836\n",
            "246       antiviral      6.165006\n",
            "151             age      6.010229\n",
            "2814           mice      5.792296\n",
            "225            anti      5.689811\n",
            "999            days      5.564090\n",
            "3477      potential      5.543532 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}